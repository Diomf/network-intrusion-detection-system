name=FilePulse-Directory-Text
connector.class=io.streamthoughts.kafka.connect.filepulse.source.FilePulseSourceConnector
topic=netflows
tasks.max=1

#filters=GroupMultilineException, ParseLog4jLog

# Multi-line filter
#filters.GroupMultilineException.negate=false
#filters.GroupMultilineException.pattern=^[\\t]
#filters.GroupMultilineException.type=io.streamthoughts.kafka.connect.filepulse.filter.MultiRowFilter

# Grok filter
#filters.ParseLog4jLog.match=\\[%{TIMESTAMP_ISO8601:logdate}\\] %{LOGLEVEL:loglevel} %{GREEDYDATA:message}
#filters.ParseLog4jLog.overwrite=message
#filters.ParseLog4jLog.source=message
#filters.ParseLog4jLog.type=io.streamthoughts.kafka.connect.filepulse.filter.GrokFilter
#filters.ParseLog4jLog.ignoreFailure=true

# File scanning
fs.scanner.class=io.streamthoughts.kafka.connect.filepulse.scanner.local.LocalFSDirectoryWalker
fs.scan.directory.path=/home/diomfeas/Desktop/heythere
fs.scan.interval.ms=4000
#fs.scan.filters=io.streamthoughts.kafka.connect.filepulse.scanner.local.filter.RegexFileListFilter
#file.filter.regex.pattern=123.txt

fs.cleanup.policy.class=io.streamthoughts.kafka.connect.filepulse.clean.LogCleanupPolicy
task.reader.class=io.streamthoughts.kafka.connect.filepulse.reader.RowFileInputReader

# Internal Reporting
internal.kafka.reporter.bootstrap.servers=localhost:9092
internal.kafka.reporter.id=FilePulse-Directory-Text
internal.kafka.reporter.topic=connect-file-pulse-status

# Track file by name
offset.strategy=name
read.max.wait.ms=5000